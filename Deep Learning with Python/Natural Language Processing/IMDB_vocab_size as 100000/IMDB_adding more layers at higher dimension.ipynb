{"cells":[{"metadata":{},"cell_type":"markdown","source":"Trying the IMDB_binary classification (taken from: https://nbviewer.jupyter.org/github/fchollet/deep-learning-with-python-notebooks/blob/master/3.5-classifying-movie-reviews.ipynb\n) with top 100000 words in the training data. \n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nkeras.__version__\n\nimport csv\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sentiment'].value_counts()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"negative    25000\npositive    25000\nName: sentiment, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_labels and test_labels are lists of 0s and 1s, where 0 stands for \"negative\" and 1 stands for \"positive\"\n\n# df['sentiment']=np.where(df['sentiment']=='positive', 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To get the maximum length of sentences in our dataset.\n\ndef max_len(df, c):\n    max_len=0\n    min_len=float(\"inf\")\n    for item in df[c]:\n        max_len=max(max_len, len(item))\n        min_len=min(min_len, len(item))\n    return max_len, min_len\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_len, min_len=max_len(df, 'review')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_len, min_len","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(13704+32)/2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['review'][3000]","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"'I bought a set of 4 DVDs for 10 bucks at my local Suncoast, which contained this movie and three other trashy horror flicks (including its sequel \"Witchcraft XI\"). So basically I paid the rock bottom price of $2.50 for this movie, if you do the math. I can\\'t exactly say I was ripped off. I have a thing for trashy horror movies, but this is the kind of trash that gives trash a bad name. The budget couldn\\'t be over $1,000 (though it appears as if they spent a total of $1.50). I know it\\'s a low-budget film, but that\\'s no excuse for totally uninspired camerawork. The film \"Blood Cult,\" though not very good, was made for an extremely low budget and still had fairly good camerawork and acting. The acting in this movie is the definition of \"effortless,\" especially from that muscular guy with the Texas accent. Everyone is pretty much reading their lines off the page. You can take that figuratively or literally. I wouldn\\'t be surprised if the script was off-camera as they were performing. I said before that I\\'ve never seen a bad English actor. This movie has quite a few bad ones. And though English movies aren\\'t always good, they always seem to have at least a level of sophistication, which is why I don\\'t see why any Englishman, or Englishwoman, would volunteer to do a home-video-style schlock flick like this. Did Merchant Ivory put a hold on their casting calls? Usually, I think people are too hard on directors and actors. Even some of the worst movies in Hollywood have some level of professionalism in the directing, acting and cinematography departments. Even when you watch a movie like \"Glitter\" you can\\'t honestly say it looks like a third-grader shot those scenes (though a third-grader could\\'ve written the script). I\\'ve seen home movies that are shot better than \"Witchcraft X,\" and that\\'s no exaggeration whatsoever. Even the gore is minimal since the filmmakers only had money to buy some fake blood on sale at Party City. Not a single effort was put into making this movie--let\\'s just sum it up like that. You get the picture. There\\'s a good deal of nudity, though that doesn\\'t save it. However, I must say that girl with the red-orange hair, who\\'s either naked or wearing a cleavage-popping outfit throughout the film, is really hot! <br /><br />My score: 1 (out of 10)'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"stopwords_special = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to remove stop words from column: review \nimport string\ndef remove_stop_words_punct(df, c):\n    sentences = []\n    output_sentences=[]\n    \n    for row in df[c]:\n        sentence = row\n        for word in stopwords_special:\n            token = \" \" + word + \" \"\n            sentence = sentence.replace(token, \" \")\n            sentence = sentence.replace(\"  \", \" \")\n        sentences.append(sentence)\n        \n    for s in sentences:\n        \n#         s.translate({ord(c): \" \" for c in ':\\'-,{!'})\n        element = s.replace('<br />','')\n        element = element.replace('\"','')\n        element = element.replace(')','')\n        element = element.replace('(','')\n        element = element.replace('{','')\n        element = element.replace('}','')\n        element = element.replace('\\'','')\n        element = element.replace('$','')\n        element = element.replace('-','')\n        element = element.replace('!','')\n        element = element.replace(':','')\n        element = element.replace(',','')\n        element = element.replace('.','')                          \n        output_sentences.append(' '.join( [w for w in element.split() if len(w)>1] ))\n\n    return output_sentences","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences=remove_stop_words_punct(df, 'review')","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Looking good after the above transformation\n\nsentences[3000]","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"'bought set DVDs 10 bucks local Suncoast contained movie three trashy horror flicks including sequel Witchcraft XI So basically paid rock bottom price 250 movie math cant exactly say ripped off thing trashy horror movies kind trash gives trash bad name The budget couldnt 1000 though appears spent total 150 know lowbudget film no excuse totally uninspired camerawork The film Blood Cult though not good made extremely low budget still fairly good camerawork acting The acting movie definition effortless especially muscular guy Texas accent Everyone pretty much reading lines off page You can take figuratively literally wouldnt surprised script offcamera performing said Ive never seen bad English actor This movie quite bad ones And though English movies arent always good always seem least level sophistication dont see Englishman Englishwoman volunteer homevideostyle schlock flick like this Did Merchant Ivory put hold casting calls? Usually think people hard directors actors Even worst movies Hollywood level professionalism directing acting cinematography departments Even watch movie like Glitter cant honestly say looks like thirdgrader shot scenes though thirdgrader couldve written script Ive seen home movies shot better Witchcraft no exaggeration whatsoever Even gore minimal since filmmakers money buy fake blood sale Party City Not single effort put making movielets just sum like that You get picture Theres good deal nudity though doesnt save it However must say girl redorange hair either naked wearing cleavagepopping outfit throughout film really hot My score out 10'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels=df['sentiment'].values.tolist()","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting 80% of the dataset into a training set and 20% as validation set\n\ntraining_portion=0.80\n# testing portion=0.10\ntrain_size = int(len(sentences)*training_portion)\n\ntrain_sentences = sentences[:train_size]\ntrain_labels = labels[:train_size]\n\ntest_sentences = sentences[train_size:]\ntest_labels = labels[train_size:]\n\nprint(train_size)\nprint(len(train_sentences))\nprint(len(train_labels))\nprint(len(test_sentences))\nprint(len(test_labels))","execution_count":10,"outputs":[{"output_type":"stream","text":"40000\n40000\n40000\n10000\n10000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_labels","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"['negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'negative',\n 'positive',\n 'negative',\n 'negative',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'positive',\n 'negative',\n ...]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"40000*.20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_portion=0.20","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\noov_tok = \"<OOV>\"\nvocab_size=100000\ntokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\ntokenizer.fit_on_texts(train_sentences)\nword_index = tokenizer.word_index\n","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(word_index)","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"188019"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_length = 6868 #average of max_len and min_len\ntrunc_type = 'post'\npadding_type = 'post'\n\ntrain_sequences = tokenizer.texts_to_sequences(train_sentences)\ntrain_padded = pad_sequences(train_sequences, maxlen=max_length, truncating=trunc_type,  padding=padding_type)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sequences = tokenizer.texts_to_sequences(test_sentences)\ntest_padded = pad_sequences(test_sequences, maxlen=max_length, truncating=trunc_type,  padding=padding_type)\n","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_train=np.array(train_labels)\n\n# y_test=np.array(test_labels)\n\nlabel_tokenizer = Tokenizer()\n\n\n","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_tokenizer","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"<keras_preprocessing.text.Tokenizer at 0x7f041a45fa50>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_tokenizer.fit_on_texts(labels)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# label_tokenizer.texts_to_sequences(train_labels)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_label_seq = np.array(label_tokenizer.texts_to_sequences(train_labels))\ntest_label_seq = np.array(label_tokenizer.texts_to_sequences(test_labels))\n","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training_label_seq","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# len(train_padded), len(training_label_seq), len(test_padded), len(test_label_seq)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"partial_x_train = train_padded[:8000]\nx_validation = train_padded[8000:]\n\n\npartial_y_train = training_label_seq[:8000]\ny_validation = training_label_seq[8000:]\n","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's try 1 hidden layer with 32 hidden units with relu activation\n\nfrom keras import models\nfrom keras import layers\nvocab_size=100000\nembedding_dim = 128\n\n# model = models.Sequential()\n# model.add(layers.Dense(128, activation='relu', input_shape=(10000,)))\n# model.add(layers.Dense(128, activation='relu'))\n# model.add(layers.Dense(128, activation='relu'))\n# model.add(layers.Dense(1, activation='sigmoid'))\n\n\nmodel = tf.keras.Sequential([tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n             tf.keras.layers.Dense(128, activation='relu'),\n             tf.keras.layers.Dense(128, activation='relu'),\n             tf.keras.layers.Dense(128, activation='relu'),\n             tf.keras.layers.Dense(128, activation='relu'),\n             tf.keras.layers.Dense(128, activation='relu'),\n             tf.keras.layers.Dense(1, activation='sigmoid')\n])\n","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.compile(optimizer='rmsprop',\n#               loss='binary_crossentropy',\n#               metrics=['accuracy'])\n\nmodel.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel.summary()","execution_count":24,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 6868, 128)         12800000  \n_________________________________________________________________\ndense (Dense)                (None, 6868, 128)         16512     \n_________________________________________________________________\ndense_1 (Dense)              (None, 6868, 128)         16512     \n_________________________________________________________________\ndense_2 (Dense)              (None, 6868, 128)         16512     \n_________________________________________________________________\ndense_3 (Dense)              (None, 6868, 128)         16512     \n_________________________________________________________________\ndense_4 (Dense)              (None, 6868, 128)         16512     \n_________________________________________________________________\ndense_5 (Dense)              (None, 6868, 1)           129       \n=================================================================\nTotal params: 12,882,689\nTrainable params: 12,882,689\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#A single hidden layer clearly is not sufficient to learn patterns from the training data and therefore performs poorly on the validation data also.\n#Remember that vicab_size=100000 words are included \n\nhistory = model.fit(partial_x_train,\n                    partial_y_train,\n                    epochs=20,\n                    batch_size=512,\n                    callbacks=[callback],\n                    validation_data=(x_validation, y_validation))\n\n\n\n# Received an InvalidArgumentError first: InvalidArgumentError:  Received a label value of 1 which is outside the valid range of [0, 1).\n# Range [0, 1) means every number between 0 and 1, excluding 1. So 1 is not a value in the range [0, 1).\n\n","execution_count":27,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n16/16 [==============================] - 63s 4s/step - loss: 8.4676 - accuracy: 0.0084 - val_loss: 7.1558 - val_accuracy: 0.0096\nEpoch 2/20\n16/16 [==============================] - 62s 4s/step - loss: 5.1520 - accuracy: 0.0086 - val_loss: 5.2531 - val_accuracy: 0.0047\nEpoch 3/20\n16/16 [==============================] - 62s 4s/step - loss: 4.3033 - accuracy: 0.0052 - val_loss: 4.9598 - val_accuracy: 0.0065\nEpoch 4/20\n16/16 [==============================] - 62s 4s/step - loss: 4.1959 - accuracy: 0.0047 - val_loss: 5.4184 - val_accuracy: 0.0051\nEpoch 5/20\n16/16 [==============================] - 62s 4s/step - loss: 4.0794 - accuracy: 0.0038 - val_loss: 5.2463 - val_accuracy: 0.0032\nEpoch 6/20\n16/16 [==============================] - 62s 4s/step - loss: 3.9825 - accuracy: 0.0023 - val_loss: 5.0974 - val_accuracy: 0.0016\nEpoch 7/20\n16/16 [==============================] - 62s 4s/step - loss: 3.8862 - accuracy: 9.0128e-04 - val_loss: 5.2888 - val_accuracy: 6.3445e-04\nEpoch 8/20\n16/16 [==============================] - 62s 4s/step - loss: 3.8250 - accuracy: 3.6000e-04 - val_loss: 5.3243 - val_accuracy: 1.8668e-04\nEpoch 9/20\n16/16 [==============================] - 62s 4s/step - loss: 3.7729 - accuracy: 1.0472e-04 - val_loss: 5.4280 - val_accuracy: 5.3723e-05\nEpoch 10/20\n16/16 [==============================] - ETA: 0s - loss: 3.7423 - accuracy: 3.7802e-05","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-fd711d316199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_data=(x_validation, y_validation))\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1134\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}