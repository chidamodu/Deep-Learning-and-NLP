{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"../input/covid19-tweets/covid19_tweets.csv\")","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"user_location\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df[\"user_location\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Percentage of null values missing in the dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf.isnull().sum()*100/len(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf[\"hashtags\"].value_counts()\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df[\"user_verified\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df[\"user_description\"].value_counts()[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df[\"source\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First, let's try to group all the records by each country possible. Let's try using regex pattern."},{"metadata":{"trusted":true},"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# %matplotlib inline\n\n# df[\"user_location\"].value_counts().plot.bar()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# df.groupby(\"user_location\").size().plot.bar()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# for i in df[\"user_location\"]:\n#     print(type(i))\n#     if str(i).startswith(\"‚àö√∫T:\"):\n#         print(\"yes\")\n#         print(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's use the outputs from pd.to_numeric and boolean indexing to find the numerical values out of the column: user_location. But these values are not the ones we are looking for and that means they are represented as string values."},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# df[pd.to_numeric(df.user_location, errors='coerce').notnull()]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import re\n# pattern=re.compile('^‚àö√∫T:')\n\n# ## THIS WAY YOU CAN CHECK FOR MULTIPLE STRINGS\n# ## LIKE\n# ## regex=re.compile('^hello|^john|^world')\n\n# for i in df[\"user_location\"]:\n#     if re.match(pattern, str(i)):\n#         print(\"Yes\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df[df[\"user_location\"]==\"‚àö√∫T: 37.322821,-121.809369\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df[df.index.isin([16893, 16894])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.loc[df[\"user_name\"]==\"Charlie Isaacs\", \"user_location\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import re\n# from collections import defaultdict\n# pattern=re.compile('√úT:')\n# d=defaultdict(list)\n\n# ## THIS WAY YOU CAN CHECK FOR MULTIPLE STRINGS\n# ## LIKE\n# ## regex=re.compile('^hello|^john|^world')\n\n# for i in df[\"user_location\"]:\n#     if re.match(pattern, str(i)):\n#         d[i].append(i)\n        \n#         d[i].append(df.index.get_loc)\n        \n#         d[df[df[\"user_location\"]==i].index.values]=\n#[df[\"user_location\"]==i].index\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in df[\"user_location\"]:\n#     if str(i).startswith('√úT:'):\n#         d[i].append(df[df[\"user_location\"]==i].index.values)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import re\n# from collections import defaultdict\n# pattern=re.compile('√úT:')\n# d=defaultdict(list)\n\n# df.index[df[\"user_location\"]=='√úT:']\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.index[df.user_location.str.contains('^√úT:')]\n\n# df.iloc[df[s].index].index\n\n# idx = df.index[df.Channel.isin(['A', 'B'])]\n\n# for i in df[\"user_location\"]:\n    \n#     df.index.get_loc(df.index[df.user_location.str.contains('^√úT:', na=False)][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#This is exactly what I wanted\ndf_userlocation=df[df['user_location'].str.contains('^√úT:') == True].user_location","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_userlocation.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_userlocation=df_userlocation.reset_index()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_userlocation.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_userlocation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_userlocation.index.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from geopy.geocoders import Nominatim\n# # create the locator\n# geolocator = Nominatim(user_agent=\"myGeocoder\")\n\n# # getting the location address\n# location = geolocator.reverse(\"52.5127, 13.3811\")\n# print(location)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# location2 = geolocator.reverse(\"51.551339,0.013024\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# location2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# location3=geolocator.reverse(\"-26.532499,28.376949\")\n# str(location3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# s=\"√úT: 52.5127, 13.3811\"\n# s.lstrip().rstrip()[4:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in df_userlocation[\"user_location\"]:\n#     location = geolocator.reverse(i.lstrip().rstrip()[4:])\n#     print(location)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# from geopy.geocoders import Nominatim\n# def lat_long_conversion(df, col1):\n#     df[\"address\"]=\"\"#let's add a new column to the same dataframe in order to add the results at appropriate indexes\n#     geolocator = Nominatim(user_agent=\"myGeocoder\")\n#     for i in range(len(df[col1])):\n#         location = geolocator.reverse(df[col1][i].lstrip().rstrip()[4:])\n#         df.loc[i, \"address\"]=str(location)#without str in the statement here it issued an error saying cannot assign a multiindex values.\n#         #that's because values are separated by commas in an address\n#     return df\n        \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_userlocation_altered=lat_long_conversion(df_userlocation, \"user_location\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_userlocation.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_userlocation[\"index\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in df_userlocation[\"user_location\"]:\n#     print(i.lstrip().rstrip()[4:])\n    \n# Observation:\n# Looks like we have some text in the column: \"wa Tatakho\"\n# Also value missing in: 33.87572,- (getting a value error for the missing value)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looks like Latitude and Longitude with values 0.0,0.0 should not be an issue\n\n# geolocator.reverse(\"0.0,0.0\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting a ValueError: Must be a coordinate pair or Point\n# geolocator.reverse(\"33.87572,-\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_userlocation.drop(\"address\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_userlocation.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_userlocation[df_userlocation[\"user_location\"].str.contains(\"wa Tatakho\")]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's remove the text from the column and also the latitude and longitude with a missing value from the column\n#but this did not work\n\n# delete_row = df_userlocation[df_userlocation[\"user_location\"]==\"√úT:kwa Tatakho\"].index\n# df_userlocation.drop(delete_row, axis=0, inplace=True)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_userlocation[df_userlocation[\"user_location\"].str.contains(\"wa Tatakho\")]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removed index=126252 from the dataframe\n# df_userlocation.drop(233, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# len(df_userlocation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_userlocation[df_userlocation[\"user_location\"].str.contains(\"wa Tatakho\")]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# df_userlocation[df_userlocation[\"user_location\"].str.contains(\"33.87572,-\")]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removed index=137030 from the dataframe\n# df_userlocation.drop(264, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# len(df_userlocation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_userlocation[df_userlocation[\"user_location\"].str.contains(\"33.87572,-\")]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom geopy.geocoders import Nominatim\n\ndef lat_long_conversion(df, col1):\n    df[\"address\"]=\"\"#let's add a new column to the same dataframe in order to add the results at appropriate indexes\n    geolocator = Nominatim(user_agent=\"myGeocoder\")\n    for i in range(len(df[col1])):\n        try:\n            location = geolocator.reverse(df[col1][i].lstrip().rstrip()[4:])\n            df.loc[i, \"address\"]=str(location)#without str in the statement here it issued an error saying cannot assign a multiindex values.\n        #that's because values are separated by commas in an address\n        except:\n            print(\"something's wrong with the coordinates {}\".format(df[col1][i].lstrip().rstrip()[4:]))\n    return df.head()\n          ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#It worked, yay!\n\nlat_long_conversion(df_userlocation, \"user_location\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_userlocation.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#saving this file to /kaggle/working/ in the output directory. saving here will save the file outside the current session so\n#can use it tomorrow. Proud of you Rockstar!\n\ndf_userlocation.to_csv(\"/kaggle/working/address_extracted.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf2=pd.read_csv(\"./address_extracted.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[[979]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"index\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2[\"index\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df2_dict = df2.set_index('index').to_dict()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df2_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# df['index'] = df['index'].apply(lambda x: df2_dict[x])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.set_index('index')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = df2.set_index('index')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.drop(\"Unnamed: 0\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.update(df2)\n# df.reset_index(inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[[979]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2=df2.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = df2.set_index('index')['address'].to_dict()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.set_index('index')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"v = df.filter(like='user_location')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"v","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[v.columns] = v.replace(m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[[979]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[[2295]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c=0\nfor i in df[\"index\"]:\n    print(df2[\"index\"][i])\n\n    if df[\"index\"][i]== df2[\"index\"][i]:\n        c+=1\n        \n# print(c)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df2[\"index\"].tolist():\n#     df2.loc[df2[\"index\"]==i, \"address\"].values[0]\n    \n    df.loc[i, [\"user_location\"]].replace(df.loc[i, [\"user_location\"]].values[0], df2.loc[df2[\"index\"]==i, \"address\"].values[0])\n    \n#     print(df.loc[i, [\"user_location\"]].values[0])\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#the above did not work either!\n\ndf.loc[[979]]","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"       user_name         user_location  \\\n979  Andri Yatim  √úT: 52.5127, 13.3811   \n\n                                      user_description         user_created  \\\n979  BLM, Everton, F1, Art, Music, Movies, Food - A...  2009-01-03 12:14:16   \n\n     user_followers  user_friends  user_favourites  user_verified  \\\n979             826          2078             2635          False   \n\n                    date                                               text  \\\n979  2020-07-25 11:59:15  Your religion is absolute bullshit if it insis...   \n\n    hashtags           source  is_retweet  \n979      NaN  Twitter Web App       False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_name</th>\n      <th>user_location</th>\n      <th>user_description</th>\n      <th>user_created</th>\n      <th>user_followers</th>\n      <th>user_friends</th>\n      <th>user_favourites</th>\n      <th>user_verified</th>\n      <th>date</th>\n      <th>text</th>\n      <th>hashtags</th>\n      <th>source</th>\n      <th>is_retweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>979</th>\n      <td>Andri Yatim</td>\n      <td>√úT: 52.5127, 13.3811</td>\n      <td>BLM, Everton, F1, Art, Music, Movies, Food - A...</td>\n      <td>2009-01-03 12:14:16</td>\n      <td>826</td>\n      <td>2078</td>\n      <td>2635</td>\n      <td>False</td>\n      <td>2020-07-25 11:59:15</td>\n      <td>Your religion is absolute bullshit if it insis...</td>\n      <td>NaN</td>\n      <td>Twitter Web App</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"         user_name         user_location  \\\n0           ·èâ·é•‚òª’¨ÍÇÖœÆ            astroworld   \n1    Tom Basile üá∫üá∏          New York, NY   \n2  Time4fisticuffs      Pewee Valley, KY   \n3      ethel mertz  Stuck in the Middle    \n4         DIPR-J&K     Jammu and Kashmir   \n\n                                    user_description         user_created  \\\n0  wednesday addams as a disney princess keepin i...  2017-05-26 05:46:42   \n1  Husband, Father, Columnist & Commentator. Auth...  2009-04-16 20:06:23   \n2  #Christian #Catholic #Conservative #Reagan #Re...  2009-02-28 18:57:41   \n3  #Browns #Indians #ClevelandProud #[]_[] #Cavs ...  2019-03-07 01:45:06   \n4  üñäÔ∏èOfficial Twitter handle of Department of Inf...  2017-02-12 06:45:15   \n\n   user_followers  user_friends  user_favourites  user_verified  \\\n0             624           950            18775          False   \n1            2253          1677               24           True   \n2            9275          9525             7254          False   \n3             197           987             1488          False   \n4          101009           168              101          False   \n\n                  date                                               text  \\\n0  2020-07-25 12:27:21  If I smelled the scent of hand sanitizers toda...   \n1  2020-07-25 12:27:17  Hey @Yankees @YankeesPR and @MLB - wouldn't it...   \n2  2020-07-25 12:27:14  @diane3443 @wdunlap @realDonaldTrump Trump nev...   \n3  2020-07-25 12:27:10  @brookbanktv The one gift #COVID19 has give me...   \n4  2020-07-25 12:27:08  25 July : Media Bulletin on Novel #CoronaVirus...   \n\n                            hashtags               source  is_retweet  \n0                                NaN   Twitter for iPhone       False  \n1                                NaN  Twitter for Android       False  \n2                        ['COVID19']  Twitter for Android       False  \n3                        ['COVID19']   Twitter for iPhone       False  \n4  ['CoronaVirusUpdates', 'COVID19']  Twitter for Android       False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_name</th>\n      <th>user_location</th>\n      <th>user_description</th>\n      <th>user_created</th>\n      <th>user_followers</th>\n      <th>user_friends</th>\n      <th>user_favourites</th>\n      <th>user_verified</th>\n      <th>date</th>\n      <th>text</th>\n      <th>hashtags</th>\n      <th>source</th>\n      <th>is_retweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>·èâ·é•‚òª’¨ÍÇÖœÆ</td>\n      <td>astroworld</td>\n      <td>wednesday addams as a disney princess keepin i...</td>\n      <td>2017-05-26 05:46:42</td>\n      <td>624</td>\n      <td>950</td>\n      <td>18775</td>\n      <td>False</td>\n      <td>2020-07-25 12:27:21</td>\n      <td>If I smelled the scent of hand sanitizers toda...</td>\n      <td>NaN</td>\n      <td>Twitter for iPhone</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Tom Basile üá∫üá∏</td>\n      <td>New York, NY</td>\n      <td>Husband, Father, Columnist &amp; Commentator. Auth...</td>\n      <td>2009-04-16 20:06:23</td>\n      <td>2253</td>\n      <td>1677</td>\n      <td>24</td>\n      <td>True</td>\n      <td>2020-07-25 12:27:17</td>\n      <td>Hey @Yankees @YankeesPR and @MLB - wouldn't it...</td>\n      <td>NaN</td>\n      <td>Twitter for Android</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Time4fisticuffs</td>\n      <td>Pewee Valley, KY</td>\n      <td>#Christian #Catholic #Conservative #Reagan #Re...</td>\n      <td>2009-02-28 18:57:41</td>\n      <td>9275</td>\n      <td>9525</td>\n      <td>7254</td>\n      <td>False</td>\n      <td>2020-07-25 12:27:14</td>\n      <td>@diane3443 @wdunlap @realDonaldTrump Trump nev...</td>\n      <td>['COVID19']</td>\n      <td>Twitter for Android</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ethel mertz</td>\n      <td>Stuck in the Middle</td>\n      <td>#Browns #Indians #ClevelandProud #[]_[] #Cavs ...</td>\n      <td>2019-03-07 01:45:06</td>\n      <td>197</td>\n      <td>987</td>\n      <td>1488</td>\n      <td>False</td>\n      <td>2020-07-25 12:27:10</td>\n      <td>@brookbanktv The one gift #COVID19 has give me...</td>\n      <td>['COVID19']</td>\n      <td>Twitter for iPhone</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DIPR-J&amp;K</td>\n      <td>Jammu and Kashmir</td>\n      <td>üñäÔ∏èOfficial Twitter handle of Department of Inf...</td>\n      <td>2017-02-12 06:45:15</td>\n      <td>101009</td>\n      <td>168</td>\n      <td>101</td>\n      <td>False</td>\n      <td>2020-07-25 12:27:08</td>\n      <td>25 July : Media Bulletin on Novel #CoronaVirus...</td>\n      <td>['CoronaVirusUpdates', 'COVID19']</td>\n      <td>Twitter for Android</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_description, text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"combined_description_text\"] = df[\"user_description\"] + df[\"text\"]","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"combined_description_text\"].head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"0    wednesday addams as a disney princess keepin i...\n1    Husband, Father, Columnist & Commentator. Auth...\n2    #Christian #Catholic #Conservative #Reagan #Re...\n3    #Browns #Indians #ClevelandProud #[]_[] #Cavs ...\n4    üñäÔ∏èOfficial Twitter handle of Department of Inf...\nName: combined_description_text, dtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"combined_description_text\"][1]","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"\"Husband, Father, Columnist & Commentator. Author of Tough Sell: Fighting the Media War in Iraq. Bush Admin Alum. Newsmax Contributor. Fmr Exec Dir NYSGOPHey @Yankees @YankeesPR and @MLB - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶ https://t.co/1QvW0zgyPu\""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['combined_description_text'].isnull().sum()","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"9466"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's try replacing null values in the column with an empty string\n\n\ndf_combined_emptystring=df['combined_description_text'].fillna('')\n","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined_emptystring.isnull().sum()","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfv = TfidfVectorizer(min_df=3,  max_features=None, \n            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n            stop_words = 'english')","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train1=df_combined_emptystring.values.tolist()","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting TF-IDF to both training and test sets (semi-supervised learning)\ntfv.fit(train1)\ntrain1_tfv =  tfv.transform(train1) ","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train1_tfv","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"<166656x423016 sparse matrix of type '<class 'numpy.float64'>'\n\twith 6672494 stored elements in Compressed Sparse Row format>"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}