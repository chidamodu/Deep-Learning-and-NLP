{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "This is a proof of concept application of Non Negative Matrix Factorization of the term frequency matrix of a corpus \n",
    "of documents so as to extract an additive model of the topic structure of the corpus. The output is a list of topics, \n",
    "each represented as a list of terms (weights are not shown).\n",
    "\n",
    "The default parameters (n_samples / n_features / n_topics) should make the example runnable in a couple of tens of \n",
    "seconds. You can try to increase the dimensions of the problem, but be aware than the time complexity is polynomial.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset and extracting TF-IDF features...\n",
      "done in 55.990s.\n",
      "Fitting the NMF model with n_samples=2000 and n_features=1000...\n",
      "done in 56.152s.\n",
      "Topic #0:\n",
      "just people don think like know say did make really time way ve right sure good going want got wrong\n",
      "\n",
      "Topic #1:\n",
      "windows use using window dos program application os drivers software help screen running ms code motif pc work ve mode\n",
      "\n",
      "Topic #2:\n",
      "god jesus bible faith does christian christians christ believe life heaven sin lord church religion true mary human belief love\n",
      "\n",
      "Topic #3:\n",
      "thanks know does mail advance hi info interested anybody email like looking help appreciated card information list send need post\n",
      "\n",
      "Topic #4:\n",
      "car new 00 bike 10 price space cars power sale good year engine years used cost miles condition great 000\n",
      "\n",
      "Topic #5:\n",
      "edu soon com send university internet ftp mail mit information article cc pub address hope program email mac blood contact\n",
      "\n",
      "Topic #6:\n",
      "file problem files format ftp win space sound read pub available program site help version image book copy save memory\n",
      "\n",
      "Topic #7:\n",
      "game team year games win play season players nhl runs toronto ll flyers division goal hockey player won defense teams\n",
      "\n",
      "Topic #8:\n",
      "drive drives hard disk card software floppy mac pc apple power computer scsi controller memory problem board mb monitor cable\n",
      "\n",
      "Topic #9:\n",
      "key chip government clipper encryption keys use public law enforcement secure phone data nsa security used clinton communications going encrypted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_topics = 10\n",
    "n_top_words = 20\n",
    "\n",
    "# Load the 20 newsgroups dataset and vectorize it. We use a few heuristics\n",
    "# to filter out useless terms early on: the posts are stripped of headers,\n",
    "# footers and quoted replies, and common English words, words occurring in\n",
    "# only one document or in at least 95% of the documents are removed.\n",
    "\n",
    "t0 = time()\n",
    "print(\"Loading dataset and extracting TF-IDF features...\")\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=n_features,\n",
    "                             stop_words='english')\n",
    "tfidf = vectorizer.fit_transform(dataset.data[:n_samples])\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model with n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "nmf = NMF(n_components=n_topics, random_state=1).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    print(\"Topic #%d:\" % topic_idx)\n",
    "    print(\" \".join([feature_names[i]\n",
    "                    for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
