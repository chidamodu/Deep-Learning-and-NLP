{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Note: the pink dashed, on both sides, sentences are the correct answers\n",
    "\n",
    "1.Question 1\n",
    "Why does sequence make a large difference when determining semantics of language?\n",
    "\n",
    "\n",
    "Because the order of words doesn’t matter\n",
    "\n",
    "\n",
    "Because the order in which words appear dictate their meaning\n",
    "\n",
    "\n",
    "-----Because the order in which words appear dictate their impact on the meaning of the sentence-----\n",
    "\n",
    "\n",
    "It doesn’t\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.Question 2\n",
    "How do Recurrent Neural Networks help you understand the impact of sequence on meaning?\n",
    "\n",
    "\n",
    "They look at the whole sentence at a time\n",
    "\n",
    "\n",
    "They shuffle the words evenly\n",
    "\n",
    "\n",
    "They don’t\n",
    "\n",
    "\n",
    "-----They carry meaning from one cell to the next-----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3.Question 3\n",
    "How does an LSTM help understand meaning when words that qualify each other aren’t necessarily beside each other in a sentence?\n",
    "\n",
    "\n",
    "-----Values from earlier words can be carried to later ones via a cell state-----\n",
    "\n",
    "They load all words into a cell state\n",
    "\n",
    "\n",
    "They don’t\n",
    "\n",
    "\n",
    "They shuffle the words randomly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4.Question 4\n",
    "What keras layer type allows LSTMs to look forward and backward in a sentence?\n",
    "\n",
    "\n",
    "Bilateral\n",
    "\n",
    "\n",
    "Unilateral\n",
    "\n",
    "\n",
    "Bothdirection\n",
    "\n",
    "\n",
    "-----Bidirectional-----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5.Question 5\n",
    "What’s the output shape of a bidirectional LSTM layer with 64 units?\n",
    "\n",
    "\n",
    "(None, 64)\n",
    "\n",
    "\n",
    "-----(None, 128)-----\n",
    "\n",
    "\n",
    "(128,1)\n",
    "\n",
    "\n",
    "(128,None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6.Question 6\n",
    "When stacking LSTMs, how do you instruct an LSTM to feed the next one in the sequence?\n",
    "\n",
    "\n",
    "Do nothing, TensorFlow handles this automatically\n",
    "\n",
    "\n",
    "-----Ensure that return_sequences is set to True only on units that feed to another LSTM-----\n",
    "\n",
    "\n",
    "Ensure that return_sequences is set to True on all units\n",
    "\n",
    "\n",
    "Ensure that they have the same number of units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7.Question 7\n",
    "If a sentence has 120 tokens in it, and a Conv1D with 128 filters with a Kernal size of 5 is passed over it, what’s the output shape?\n",
    "\n",
    "\n",
    "(None, 116, 124)\n",
    "\n",
    "\n",
    "(None, 120, 124)\n",
    "\n",
    "\n",
    "-----(None, 116, 128)-----\n",
    "\n",
    "\n",
    "(None, 120, 128)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8.Question 8\n",
    "What’s the best way to avoid overfitting in NLP datasets?\n",
    "\n",
    "\n",
    "Use LSTMs\n",
    "\n",
    "\n",
    "Use GRUs\n",
    "\n",
    "\n",
    "Use Conv1D\n",
    "\n",
    "\n",
    "-----None of the above-----\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
